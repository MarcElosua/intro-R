---
title: "Day-4: Single Cell Analysis with Bioconductor"
author: "Marc Elosua-Bayés"
date: "3/15/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
In this Rmd we are going to keep going from where we left off last session with our PBMC data. TOday we are going to focus on dimensionality reduction, batch correction, clustering and cluster annotation! We are using [OSCA](http://bioconductor.org/books/3.13/OSCA/) as the backbone of these sessions, we can't go in depth in all the steps but feel free to read each chapter of the book in detail for each step as you analyze your data. You can find a workflow analyzing this dataset [here](http://bioconductor.org/books/3.13/OSCA.workflows/unfiltered-human-pbmcs-10x-genomics.html).

## Libraries
```{r libraries}
library(tidyverse)
# install.packages("patchwork")
library(patchwork)
# install.packages("BiocManager")
# BiocManager::install(pkgs = c("SingleCellExperiment", "DropletUtils", "scran", "scater", "scuttle", "uwot", "rtracklayer"))
library(SingleCellExperiment)
library(DropletUtils)
library(scran)
library(scater)
library(glue)
```

## Load data
The data we are going to use was generated by 10X genomics and consists of ~3k PBMCs. It can be downloaded from the 10X [website](https://support.10xgenomics.com/single-cell-gene-expression/datasets/2.1.0/pbmc4k?) and you can find it in the folder *data-day4*.
```{r load}
path <- "data-day4/filtered_gene_bc_matrices"
sce <- read10xCounts(
    sample = path,
    col.names = TRUE,
    sample.names = "pbmc")
rownames(sce) <- rowData(sce)$Symbol
```

## Normalization & Dim reduction
Lastly we are going to visualize where these cells fall on the UMAP. In order to do this we need to do a couple of processing steps that we will go a bit deeper into next week so just believe me until then.

### Library size normalization
See [OSCA](http://bioconductor.org/books/3.13/OSCA.basic/normalization.html)
Library size normalization is the simplest strategy for performing scaling normalization. We define the library size as the total sum of counts across all genes for each cell, the expected value of which is assumed to scale with any cell-specific biases. The “library size factor” for each cell is then directly proportional to its library size where the proportionality constant is defined such that the mean size factor across all cells is equal to 1. This definition ensures that the normalized expression values are on the same scale as the original counts, which is useful for interpretation - especially when dealing with transformed data (see Section 2.5).

Not all the cells have the same amount of RNA selected
```{r}
ggplot() +
    geom_histogram(aes(colSums(counts(sce)))) +
    scale_x_log10() +
    labs(title = "UMI per cell distribution") +
    theme_classic()
```

We need to normalize the gene expression.
```{r}
# Log Normalize the counts
sce <- logNormCounts(sce)
```

### Feature Selection

See [OSCA](http://bioconductor.org/books/3.13/OSCA.basic/feature-selection.html)
The choice of genes to use in this calculation has a major impact on the behavior of the metric and the performance of downstream methods. We want to select genes that contain useful information about the biology of the system while removing genes that contain random noise. This aims to preserve interesting biological structure without the variance that obscures that structure, and to reduce the size of the data to improve computational efficiency of later steps.

The simplest approach to feature selection is to select the most variable genes based on their expression across the population. This assumes that genuine biological differences will manifest as increased variation in the affected genes, compared to other genes that are only affected by technical noise or a baseline level of “uninteresting” biological variation
```{r}
# Model the gene variance
dec <- modelGeneVar(sce)

# If we have multiple batches we can do the following to account for inter-batch variability
# dec <- modelGeneVar(sce, block = sce$batch)

# Extract metadata from S4 object
fit <- metadata(dec)
# Chech that the Gene variance modeling hasn't yielded an overfitted trend when there is a few high abundance genes that are higly variable
plot(fit$mean, fit$var,
    xlab = "Mean of log-expression",
    ylab = "Variance of log-expression") 
curve(fit$trend(x), col = "dodgerblue", add = TRUE, lwd = 2)
```

Selecting the most meaningful genes biologically - we assume they are going to be the most variable
```{r}
hvg <- getTopHVGs(dec, n = 3000, fdr.threshold = 0.05)
# Show top10 most variable genes
hvg[1:10]
```

### Dimensionality Reduction
See [OSCA](http://bioconductor.org/books/3.13/OSCA.basic/dimensionality-reduction.html)

Dimensionality reduction aims to reduce the number of separate dimensions in the data. This is possible because different genes are correlated if they are affected by the same biological process. Thus, we do not need to store separate information for individual genes, but can instead compress multiple features into a single dimension(Langfelder and Horvath 2007). This reduces computational work in downstream analyses like clustering, as calculations only need to be performed for a few dimensions rather than thousands of genes; reduces noise by averaging across multiple genes to obtain a more precise representation of the patterns in the data; and enables effective plotting of the data, for those of us who are not capable of visualizing more than 3 dimensions.

#### PCA
Principal components analysis (PCA) discovers axes in high-dimensional space that capture the largest amount of variation. By definition, the top PCs capture the dominant factors of heterogeneity in the data set. In the context of scRNA-seq, our assumption is that biological processes affect multiple genes in a coordinated manner. This means that the earlier PCs are likely to represent biological structure as more variation can be captured by considering the correlated behavior of many genes. By comparison, random technical or biological noise is expected to affect each gene independently. There is unlikely to be an axis that can capture random variation across many genes, meaning that noise should mostly be concentrated in the later PCs. This motivates the use of the earlier PCs in our downstream analyses, which concentrates the biological signal to simultaneously reduce computational work and remove noise.
```{r}
sce <- runPCA(sce, subset_row = hvg)

# Percentage of variance explained is tucked away in the attributes.
percent.var <- attr(reducedDim(sce), "percentVar")
ggplot() +
    geom_point(aes(x = seq_len(length(percent.var)), y = percent.var)) +
    labs(x = "PC", y = "Variance explained (%)") +
    theme_classic()
```

It seems like the 1st PC explains 40% of the variability in the data, we can take a look at which genes are driving this:
```{r}
pca <- reducedDim(sce, "PCA")
# Extract the weights for each gene for each PC
pca_weights <- attr(pca, "rotation")

# Look at the genes corresponding to the top PC
sort(pca_weights[, "PC1"], decreasing = TRUE)[1:10]
sort(pca_weights[, "PC2"], decreasing = TRUE)[1:10]
sort(pca_weights[, "PC3"], decreasing = TRUE)[1:20]
sort(pca_weights[, "PC4"], decreasing = TRUE)[1:10]
sort(pca_weights[, "PC5"], decreasing = TRUE)[1:10]
```

We can look at how the Principal Components actually separate the cells by their expression
Look at the cells on the UMAP
```{r}
# PC 1 gene
plotPCA(sce, colour_by = "CD3D")

# PC 2 gene
plotPCA(sce, colour_by = "CD79A")
```

#### UMAP embedding
This attempts to find a low-dimensional representation of the data that preserves the distances between each point and its neighbors in the high-dimensional space. Unlike PCA, it is not restricted to linear transformations, nor is it obliged to accurately represent distances between distant populations. This means that it has much more freedom in how it arranges cells in low-dimensional space, enabling it to separate many distinct clusters in a complex population
```{r}
sce <- runUMAP(
    sce,
    dimred = "PCA",
    ncomponents = 3,
    pca = 20)
```

### Clustering
See [OSCA](http://bioconductor.org/books/3.13/OSCA.basic/clustering.html)
Clustering is an unsupervised learning procedure that is used to empirically define groups of cells with similar expression profiles. Its primary purpose is to summarize complex scRNA-seq data into a digestible format for human interpretation. This allows us to describe population heterogeneity in terms of discrete labels that are easily understood, rather than attempting to comprehend the high-dimensional manifold on which the cells truly reside. After annotation based on marker genes, the clusters can be treated as proxies for more abstract biological concepts such as cell types or states.

We are going to use Leiden clustering but there are a lot of other clustering algorithms out there as explaine in `OSCA`
```{r}
################################################
### Make graph with shared nearest neighbors ###
################################################
# With large datasets we can change k to a larger number it increases the connectivity of the graph and should reduce the number of clusters
# https://support.bioconductor.org/p/111501/
g <- buildSNNGraph(
    sce,
    use.dimred = "PCA",
    k = 10)

###################
### Get cluster ###
###################
# Get clusters from the graph using the leiden algorithm
# Run several resolutions to see which one fits best the data
res <- c(0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.25)
clust <- lapply(res, function(r) {
    print(r)
    tmp <- igraph::cluster_leiden(
        graph = g,
        objective_function = "modularity",
        resolution_parameter = r)$membership
    as.character(tmp)
    })

# Add names
names(clust) <- glue("leiden_{res}")

# Add clusterings to sce
colData(sce) <- cbind(colData(sce), data.frame(clust))
```

Look at the clustering on the UMAP
```{r fig.width=18, fig.height=18}
lapply(names(clust), function(i) {
    plotUMAP(
        sce,
        colour_by = i)
}) %>% wrap_plots(., ncol = 3)

colLabels(sce) <- clust[["leiden_0.25"]]
```

### Markers Genes
The most straightforward approach to marker gene detection involves testing for differential expression between clusters. If a gene is strongly DE between clusters, it is likely to have driven the separation of cells in the clustering algorithm. Several methods are available to quantify the differences in expression profiles between clusters and obtain a single ranking of genes for each cluster.
```{r}
mgs <- scran::scoreMarkers(
    sce,
    groups = colData(sce)[, "leiden_0.25"],
    # Numeric scalar specifying the log-fold change threshold to compute effect sizes against.
    lfc = 0.25)

# Join mgs to a dataframe
mgs_df <- lapply(names(mgs), function(i) {
    
    mgs[[i]] %>%
        data.frame() %>%
        round(3) %>% 
        tibble::rownames_to_column("gene") %>%
        # Filter those informative genes
        filter(max.AUC > 0.75 | max.logFC.detected > 0.75) %>%
        arrange(desc(mean.AUC)) %>%
        mutate(cluster = as.character(i))
    }) %>%
    bind_rows()
```

Save marker genes to spreadsheet
```{r}
cn <- c("cluster", "gene", "mean.logFC.detected",
    "self.detected","other.detected",
    "mean.logFC.cohen", "mean.AUC")

out_file <- "msg_pbmc.xlsx"
file.remove(out_file)

mgs_ls <- lapply(sort(unique(mgs_df$cluster)), function(clust) {
    mgs_df[, cn] %>%
            dplyr::filter(cluster == clust & self.detected > 0.1) %>%
            dplyr::arrange(dplyr::desc(mean.AUC))
  })

names(mgs_ls) <- glue("cluster-{sort(unique(mgs_df$cluster))}")
openxlsx::write.xlsx(mgs_ls, file = out_file)
```

### Cluster Annotation
```{r}
colData(sce) <- colData(sce) %>%
    data.frame() %>%
    dplyr::mutate(
        annotation_lvl2 = dplyr::case_when(
            leiden_0.25 == 1 ~ "",
            leiden_0.25 == 2 ~ "",
            leiden_0.25 == 3 ~ "",
            leiden_0.25 == 4 ~ "",
            leiden_0.25 == 5 ~ "",
            leiden_0.25 == 6 ~ "",
            TRUE ~ "WARNING"
            )
        ) %>%
    DataFrame()

```


## Session Info
```{r}
sessionInfo()
```
